{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3198b7b7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Fine Tuning\"\n",
    "author: \"Jaume Amores\"\n",
    "format:\n",
    "  revealjs:\n",
    "    scrollable: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f1d25",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Using LangSmith to Support Fine-tuning\n",
    "\n",
    "[blog post](https://blog.langchain.com/using-langsmith-to-support-fine-tuning-of-open-source-llms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f724fe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Scenarios\n",
    "\n",
    "- Open Source LLM + Fine-tuning can outperform foundational SOTA models (e.g., ChatGPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de46412",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## When to fine-tune\n",
    "\n",
    "- Two ways of learning:\n",
    "    - Weights: pre-training, fine-tuning\n",
    "    - Prompting, via RAG.\n",
    "- Analogy:\n",
    "    - Fine-tuning is like studying one week in advance.\n",
    "    - Prompting is like taking exam with open notes.\n",
    "- Not Good for:\n",
    "    - Learning new knowledge. Can increase hallucinations.\n",
    "- Good for:\n",
    "    - Specialized tasks, in similar ways to RAG.\n",
    "        - With many examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6eab5",
   "metadata": {},
   "source": [
    "## When to fine-tune, more analogies\n",
    "\n",
    "- Zero shot learning: describe task with words.\n",
    "- Few shot learning: give few examples of solving task in prompt (e.g., via RAG or manually)\n",
    "- Fine tuning: allow person to practice task.\n",
    "    - In applications with concrete well-defined tasks where it is possible to collect a lot of data and \"practice\" on it.\n",
    "- [Karpathy's tweet](https://x.com/karpathy/status/1655994367033884672?ref=blog.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40775fc3",
   "metadata": {},
   "source": [
    "## Fine-tuning vs others complete guide\n",
    "\n",
    "Possibilities along two axis:\n",
    "- Complexity / Cost dimension (higher to lower):\n",
    "    - From scratch training\n",
    "    - Reinforcement Learning from Human Feedback\n",
    "    - Fine Tuning, Retrieval Assisted Generation => Problems Addressed dimension: Form problems - Fine Tuning, Factual Problems - RAG\n",
    "    - Static / Dynamic Example Selection\n",
    "    - Manual / Automatic Prompt Tuning\n",
    "\n",
    "- Fine tuning is good at:\n",
    "    - Learning the style or form of language.\n",
    "    - Examples:\n",
    "        - Pure autoregressive model on Q & A, since there's plenty of Q&A data.\n",
    "        - Pure autoregressive model on instruction following, since there's plenty of data.\n",
    "        - Imitate style, e.g., Shakespeare, since there is lot of training material. Also, legal jargon, claim responses\n",
    "        - Imitate structure / format, like resumes.\n",
    "- It is not good at:\n",
    "    - Learning new concepts that do not exist in the base knowledge of the foundational model.\n",
    "    - Example:\n",
    "        - Replace Romeo with Bob in a set of texts and fine-tune. See if it forgets association of Romeo with Juliet and learns that it is Bob who was with Juliet. Fails because the *Romeo* concept is ingrained in the base knowledge.\n",
    "        - Answer questions like \"who said to be or not to be\" after fine-tuning on set of Shakespeare works. \n",
    "            - Better use search engine (RAG) to retrieve those answers and inject them in prompt for LLM.\n",
    "            - Question: what does LLM add here, if the search engine is already finding relevant answers? Remove FP?\n",
    "\n",
    "- [Fine tuning is for form, not facts](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848838e3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Fine-tuning - OpenAI example\n",
    "\n",
    "[colab](https://colab.research.google.com/drive/1YCyDHPSl0d_ULubCVshrP5hLqUCorr7d?usp=sharing&ref=blog.langchain.com#scrollTo=A-8dt5qqtpgM)\n",
    "\n",
    "- Transform message format from LangSmith to OpenAI:\n",
    "    ```python\n",
    "    [example.inputs, example.outputs for example in client.list_examples (dataset_name=name_dataset)]\n",
    "    example.inputs[\"sentence\"] # string\n",
    "    example.outputs[\"cluster\"] # dictionary: text_dict = json.dumps(example.outputs[\"cluster\"])\n",
    "    open_ai_format = [\n",
    "        {\"role\": \"user\", \"content\": \"...\" + sentence},\n",
    "        {\"role\": \"assistant\", \"content\": text_dict}\n",
    "    ]\n",
    "    data = [open_ai_format(in,out) for ...]\n",
    "    ```\n",
    "- Write into binary file:\n",
    "```python\n",
    "binary_file = BytesIO()\n",
    "for m in data:\n",
    "    binary_file.write (json.dumps({\"messages\": m}) + \"\\n\")\n",
    "training_file=openai.File.create (file=binary_file, purpose=\"fine-tune\")\n",
    "```\n",
    "- Train:\n",
    "    ```python\n",
    "    job = openai.FineTuningJob.create (training_file=training_file.id, model=\"gpt-3.5-turbo\")\n",
    "    while True:\n",
    "        ftj = openai.FineTuningJob.retrieve (job.id)\n",
    "        if ftj.fine_tuned_model is None:\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            break\n",
    "    ```\n",
    "- Fine-Tuning chain:\n",
    "    ```python\n",
    "    prompt = prompts.ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"extract triplets from {sentence}\")\n",
    "        ]\n",
    "    )\n",
    "    llm = chat_models.ChatOpenAI(model=ftj.fine_tuned_model, temperature=0)\n",
    "    fine_tuned_chain = prompt | llm\n",
    "\n",
    "    # later we'll do:\n",
    "    results = await client.arun_on_dataset (\n",
    "        validation_dataset_name, # here is where the examples with format example.inputs[\"sentence\"] are taken from, and this sentence field is used by the prompt template to get triplets\n",
    "        fine_tuned_chain,\n",
    "        evaluation=config, # we will build a config object from an evaluation chain below\n",
    "    )\n",
    "    ```\n",
    "\n",
    "- Evaluation chain:\n",
    "    - `eval_prompt` for model: you are an evaluator...\n",
    "    - reasoning capability ontop of evaluation score: `commit_grade` function, defined through a dictionary schema:\n",
    "    - transforming obtained reasoning text into structured dict through `normalize_grade` function\n",
    "    ```python\n",
    "        eval_chain = (\n",
    "            eval_prompt # this is where we obtain a score, by asking it to the following model in the chain\n",
    "            | ChatOpenAI (model=\"gpt-4\", temperature=0).bind (functions=[commit_grade_schema]) # this is where we obtain a reasoning in addition to a score\n",
    "            | normalize_grade # this is where we get a structured output\n",
    "        )\n",
    "    ```\n",
    "- Evaluator class:\n",
    "    ```python\n",
    "    class EvaluateTriplets (StringEvaluator):\n",
    "        ...\n",
    "        def _evaluate_strings (\n",
    "            self,\n",
    "            *,\n",
    "            prediction, \n",
    "            # ... string fields used below in input dict\n",
    "            **kwargs,\n",
    "        ):\n",
    "            callbacks = kwargs.get(\"callbacks\")\n",
    "            return eval_chain.invoke (\n",
    "                {\"prediction\": prediction, \"reference\": reference, \"input\": input},\n",
    "                {\"callbacks\": callbacks}\n",
    "            )\n",
    "\n",
    "        config = smith.RunEvalConfig (custom_evaluators=[EvaluateTriplets()])\n",
    "    ```\n",
    "- Comparison vs few-shot examples.\n",
    "    - Differences: \n",
    "        - prompt: in addition to current sentence to be transformed into triplet, it includes few examples of inputs and desired outputs, using `partials`\n",
    "        - model: pre-trained (not fine-tuned) chat gpt model\n",
    "    \n",
    "```python\n",
    "for i in example:\n",
    "    messages.extend([\n",
    "        (\"human\", \"... {input_%d}\"%i),\n",
    "        (\"ai\", \"{output_%d}\"%i),\n",
    "    ])\n",
    "    partial[\"input_%d\" %i] = first_5[i].inputs[\"sentence\"]\n",
    "    partial[\"output_%d\" %i] = json.dumps(first_5[i].outputs[\"clusters\"])\n",
    "messages.append((\"human\", \"...{sentence}\"))\n",
    "prompts.ChatPromptTemplate.from_messages (\n",
    "    messages\n",
    ").partial (\n",
    "    **partials\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26aa8f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Quantization, LoRA and qLoRA\n",
    "\n",
    "- Model quantization: fit model (e.g., 7B Llama) in memory.\n",
    "- LoRA: efficiently fine-tune model by reducing number of parameters to be trained \n",
    "- qLoRA: same, but deals with quantized models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43102a",
   "metadata": {},
   "source": [
    "# Further reading\n",
    "\n",
    "- [Is Fine-Tuning Still Valuable?](https://hamel.dev/blog/posts/fine_tuning_valuable.html)\n",
    "- [When and Why to Fine Tune](https://www.youtube.com/watch?v=cPn0nHFsvFg)\n",
    "- [From Prompt to Model: Fine-tuning when you've already deployed LLMs in prod](https://www.youtube.com/watch?v=4EPZZkVrXC4)\n",
    "- [Deploying Fine-Tuned Models](https://www.youtube.com/watch?v=GzEcyBykkdo)\n",
    "- [Fine Tuning OpenAI Models - Best Practices](https://www.youtube.com/watch?v=Q0GSZD0Na1s)\n",
    "- [Fine-Tuning with Axolotl](https://www.youtube.com/watch?v=mmsa4wDsiy0)\n",
    "- [Why fine-tuning is dead](https://www.youtube.com/watch?v=h1c_jmk97Ss)\n",
    "- [Fine-Tuning Llama 3 and Using It Locally: A Step-by-Step Guide](https://www.datacamp.com/tutorial/llama3-fine-tuning-locally)\n",
    "- [RAG vs Fine-Tuning: A Comprehensive Tutorial with Practical Examples](https://www.datacamp.com/tutorial/rag-vs-fine-tuning?utm_cid=19589720821&utm_aid=157098104375&utm_campaign=230119_1-ps-other~dsa-tofu~all_2-b2c_3-emea_4-prc_5-na_6-na_7-le_8-pdsh-go_9-nb-e_10-na_11-na&utm_loc=9212664-&utm_mtd=-c&utm_kw=&utm_source=google&utm_medium=paid_search&utm_content=ps-other~emea-en~dsa~tofu~tutorial~artificial-intelligence&gad_source=1&gad_campaignid=19589720821&gbraid=0AAAAADQ9WsFIxTj2FMxHfYtkNv25bmuXQ&gclid=Cj0KCQiA9t3KBhCQARIsAJOcR7wj9NfQPsOqKHX3h1x-Tiff_LxQP22G2oVC6YC5A8lgWagBU5tdXlEaAkmlEALw_wcB)\n",
    "- [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)\n",
    "- [Supervised fine-tuning - OpenAI](https://platform.openai.com/docs/guides/supervised-fine-tuning)\n",
    "    - [Model optimization - OpenAI](https://platform.openai.com/docs/guides/model-optimization)\n",
    "- [Using LangSmith to Support Fine-tuning - Colab's notebooks]\n",
    "    - [With Llama](https://colab.research.google.com/drive/1tpywvzwOS74YndNXhI8NUaEfPeqOc7ub?usp=sharing&ref=blog.langchain.com)\n",
    "    - [OpenAI](https://colab.research.google.com/drive/1YCyDHPSl0d_ULubCVshrP5hLqUCorr7d?usp=sharing&ref=blog.langchain.com)\n",
    "- [Tuna for synthetic dataset generation for fine-tuning](https://blog.langchain.com/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/)\n",
    "    - [Demo](https://blog.langchain.com/fine-tuning-chatgpt-surpassing-gpt-4-summarization/)\n",
    "- [LIMA: curating small training datasets](https://arxiv.org/abs/2305.11206?ref=blog.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56ff3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg2",
   "language": "python",
   "name": "lg2"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
