{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3198b7b7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Fine Tuning\"\n",
    "author: \"Jaume Amores\"\n",
    "format:\n",
    "  revealjs:\n",
    "    scrollable: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f1d25",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Using LangSmith to Support Fine-tuning\n",
    "\n",
    "[blog post](https://blog.langchain.com/using-langsmith-to-support-fine-tuning-of-open-source-llms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f724fe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Scenarios\n",
    "\n",
    "- Open Source LLM + Fine-tuning can outperform foundational SOTA models (e.g., ChatGPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de46412",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## When to fine-tune\n",
    "\n",
    "- Two ways of learning:\n",
    "    - Weights: pre-training, fine-tuning\n",
    "    - Prompting, via RAG.\n",
    "- Analogy:\n",
    "    - Fine-tuning is like studying one week in advance.\n",
    "    - Prompting is like taking exam with open notes.\n",
    "- Not Good for:\n",
    "    - Learning new knowledge. Can increase hallucinations.\n",
    "- Good for:\n",
    "    - Specialized tasks, in similar ways to RAG.\n",
    "        - With many examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6eab5",
   "metadata": {},
   "source": [
    "## When to fine-tune, more analogies\n",
    "\n",
    "- Zero shot learning: describe task with words.\n",
    "- Few shot learning: give few examples of solving task in prompt (e.g., via RAG or manually)\n",
    "- Fine tuning: allow person to practice task.\n",
    "    - In applications with concrete well-defined tasks where it is possible to collect a lot of data and \"practice\" on it.\n",
    "- [Karpathy's tweet](https://x.com/karpathy/status/1655994367033884672?ref=blog.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40775fc3",
   "metadata": {},
   "source": [
    "## Fine-tuning vs others complete guide\n",
    "\n",
    "Possibilities along two axis:\n",
    "- Complexity / Cost dimension (higher to lower):\n",
    "    - From scratch training\n",
    "    - Reinforcement Learning from Human Feedback\n",
    "    - Fine Tuning, Retrieval Assisted Generation => Problems Addressed dimension: Form problems - Fine Tuning, Factual Problems - RAG\n",
    "    - Static / Dynamic Example Selection\n",
    "    - Manual / Automatic Prompt Tuning\n",
    "\n",
    "- Fine tuning is good at:\n",
    "    - Learning the style or form of language.\n",
    "    - Examples:\n",
    "        - Pure autoregressive model on Q & A, since there's plenty of Q&A data.\n",
    "        - Pure autoregressive model on instruction following, since there's plenty of data.\n",
    "        - Imitate style, e.g., Shakespeare, since there is lot of training material. Also, legal jargon, claim responses\n",
    "        - Imitate structure / format, like resumes.\n",
    "- It is not good at:\n",
    "    - Learning new concepts that do not exist in the base knowledge of the foundational model.\n",
    "    - Example:\n",
    "        - Replace Romeo with Bob in a set of texts and fine-tune. See if it forgets association of Romeo with Juliet and learns that it is Bob who was with Juliet. Fails because the *Romeo* concept is ingrained in the base knowledge.\n",
    "        - Answer questions like \"who said to be or not to be\" after fine-tuning on set of Shakespeare works. \n",
    "            - Better use search engine (RAG) to retrieve those answers and inject them in prompt for LLM.\n",
    "            - Question: what does LLM add here, if the search engine is already finding relevant answers? Remove FP?\n",
    "\n",
    "- [Fine tuning is for form, not facts](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43102a",
   "metadata": {},
   "source": [
    "# Further reading\n",
    "\n",
    "- [Is Fine-Tuning Still Valuable?](https://hamel.dev/blog/posts/fine_tuning_valuable.html)\n",
    "- [When and Why to Fine Tune](https://www.youtube.com/watch?v=cPn0nHFsvFg)\n",
    "- [From Prompt to Model: Fine-tuning when you've already deployed LLMs in prod](https://www.youtube.com/watch?v=4EPZZkVrXC4)\n",
    "- [Deploying Fine-Tuned Models](https://www.youtube.com/watch?v=GzEcyBykkdo)\n",
    "- [Fine Tuning OpenAI Models - Best Practices](https://www.youtube.com/watch?v=Q0GSZD0Na1s)\n",
    "- [Fine-Tuning with Axolotl](https://www.youtube.com/watch?v=mmsa4wDsiy0)\n",
    "- [Why fine-tuning is dead](https://www.youtube.com/watch?v=h1c_jmk97Ss)\n",
    "- [Fine-Tuning Llama 3 and Using It Locally: A Step-by-Step Guide](https://www.datacamp.com/tutorial/llama3-fine-tuning-locally)\n",
    "- [RAG vs Fine-Tuning: A Comprehensive Tutorial with Practical Examples](https://www.datacamp.com/tutorial/rag-vs-fine-tuning?utm_cid=19589720821&utm_aid=157098104375&utm_campaign=230119_1-ps-other~dsa-tofu~all_2-b2c_3-emea_4-prc_5-na_6-na_7-le_8-pdsh-go_9-nb-e_10-na_11-na&utm_loc=9212664-&utm_mtd=-c&utm_kw=&utm_source=google&utm_medium=paid_search&utm_content=ps-other~emea-en~dsa~tofu~tutorial~artificial-intelligence&gad_source=1&gad_campaignid=19589720821&gbraid=0AAAAADQ9WsFIxTj2FMxHfYtkNv25bmuXQ&gclid=Cj0KCQiA9t3KBhCQARIsAJOcR7wj9NfQPsOqKHX3h1x-Tiff_LxQP22G2oVC6YC5A8lgWagBU5tdXlEaAkmlEALw_wcB)\n",
    "- [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)\n",
    "- [Supervised fine-tuning - OpenAI](https://platform.openai.com/docs/guides/supervised-fine-tuning)\n",
    "    - [Model optimization - OpenAI](https://platform.openai.com/docs/guides/model-optimization)\n",
    "- [Using LangSmith to Support Fine-tuning - Colab's notebooks]\n",
    "    - [With Llama](https://colab.research.google.com/drive/1tpywvzwOS74YndNXhI8NUaEfPeqOc7ub?usp=sharing&ref=blog.langchain.com)\n",
    "    - [OpenAI](https://colab.research.google.com/drive/1YCyDHPSl0d_ULubCVshrP5hLqUCorr7d?usp=sharing&ref=blog.langchain.com)\n",
    "- [Tuna for synthetic dataset generation for fine-tuning](https://blog.langchain.com/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/)\n",
    "    - [Demo](https://blog.langchain.com/fine-tuning-chatgpt-surpassing-gpt-4-summarization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56ff3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg2",
   "language": "python",
   "name": "lg2"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
