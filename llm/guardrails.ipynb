{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3198b7b7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Guardrails\"\n",
    "author: \"Jaume Amores\"\n",
    "format:\n",
    "  revealjs:\n",
    "    scrollable: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aaeb35",
   "metadata": {},
   "source": [
    "# Guardrails - LangChain\n",
    "\n",
    "[link](https://docs.langchain.com/oss/python/langchain/guardrails)\n",
    "\n",
    "## When\n",
    "\n",
    "- Removing violations of rules / regulation\n",
    "- Protecting from harmful actions\n",
    "\n",
    "## How\n",
    "- using middleware: before agent, before / after model, around function calls\n",
    "- types: deterministic (rules, functions...), model-based\n",
    "- custom guardrails or builtin guardrails for common use cases.\n",
    "\n",
    "## Builtin guardrails\n",
    "\n",
    "- PII detection (e.g., email, credit card, ...)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c759a5f",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "- [Guardrails - DeepLearning.AI course](https://www.deeplearning.ai/short-courses/safe-and-reliable-ai-via-guardrails/)\n",
    "- [Essential Guide to LLM Guardrails: Llama Guard, NeMo - Medium post](llm_guardrails.pdf)\n",
    "- [How to implement LLM guardrails - OpenAI cookbook](https://cookbook.openai.com/examples/how_to_use_guardrails)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg2",
   "language": "python",
   "name": "lg2"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
