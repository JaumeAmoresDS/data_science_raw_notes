{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3198b7b7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Prompt Engineering\"\n",
    "author: \"Jaume Amores\"\n",
    "format:\n",
    "  revealjs:\n",
    "    scrollable: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f41009",
   "metadata": {},
   "source": [
    "# Prompt Engineering - Parlance Education\n",
    "\n",
    "[link](https://parlance-labs.com/education/prompt_eng/berryman.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3eeb9b",
   "metadata": {},
   "source": [
    "## Few shot prompting\n",
    "\n",
    "- Basic intuition: establish a pattern\n",
    "    - Establish predicted ouput from multiple example patterns (predict words ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7758d0",
   "metadata": {},
   "source": [
    "## Chain of thought reasoning\n",
    "- In the examples provided, we include the AI response to each answer be a reasoning text. This will teach the model to use this form of reasoning for answering the final question.\n",
    "- Advantages: \n",
    "    - there is no leaking into the answer\n",
    "    - we don't need many examples, just an explanation of the pattern to be followed (i.e., in this case, let's \"think step by step\" and an example of doing so)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad9402c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Document mimicry\n",
    "\n",
    "- Give context by writing a transcript-style document where the question is embedded, so that the model can predict what the continuation will be.\n",
    "- It tells a story to condition a particular response\n",
    "    - in a similar way that many transcripts have an introductory lead that explains what the transcript is about\n",
    "- Use motifs that are common online (since the model has been trained on those)\n",
    "    - Example: markdown to establish structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a48b25",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## LLMs are dumb mechanical humans\n",
    "\n",
    "- Understand better when you use familiar language and constructs.\n",
    "- Get distracted. Don't fill the prompt with lots of \"just in case\" information.\n",
    "    - Filling prompt with information that *might* be useful to the model is a mistake.\n",
    "    - Examples where intermediate context gets so long that the model forgets the original request and continues filling that intermediate context in its response.\n",
    "- They aren't psychic. If the information is not in the training set or in the prompt, they don't know it.\n",
    "- If you look at the prompt and can't make sense of it, a LLM is hopeless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2164822",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    %% ========= STYLES =========\n",
    "    classDef userNode fill:#E3F2FD,stroke:#1565C0,stroke-width:2px,color:#0D47A1;\n",
    "    classDef appNode  fill:#FFF9C4,stroke:#F9A825,stroke-width:2px,color:#3E2723;\n",
    "    classDef llmNode  fill:#E8F5E9,stroke:#2E7D32,stroke-width:2px,color:#1B5E20;\n",
    "\n",
    "    %% ========= NODES =========\n",
    "    USER[\"ðŸ‘¤ User\"]\n",
    "    APP(\"Application<br/><br/>â¬† transform user problem<br/>into model domain<br/><br/>â¬‡ transform completion<br/>into solution/update<br/>for user\")\n",
    "    LLM[\"ðŸ§  LLM\"]\n",
    "\n",
    "    %% ========= FLOW =========\n",
    "    USER -- \"user problem\" --> APP\n",
    "    APP  -- \"prompt\"       --> LLM\n",
    "    LLM  -- \"completion\"   --> APP\n",
    "    APP  -- \"solution\"     --> USER\n",
    "\n",
    "    %% ========= CLASS ASSIGNMENTS =========\n",
    "    class USER userNode;\n",
    "    class APP appNode;\n",
    "    class LLM llmNode;\n",
    "\n",
    "    %% Dashed links for a sense of motion\n",
    "    linkStyle 0,1,2,3 stroke-width:2px,stroke-dasharray:5 5;\n",
    "\n",
    "    %% style D fill:#FFD966,stroke:#333,stroke-width:2px,color:#000\n",
    "    %% style D_note fill:none,stroke:none,color:#FFFFFF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985368e9",
   "metadata": {},
   "source": [
    "## Creating the prompt\n",
    "\n",
    "Steps:\n",
    "- Collect context \n",
    "    - Useful information that is not in training already.\n",
    "- Ranking context according to its importance\n",
    "    - Because we won't be able to fit it all.\n",
    "- Trimming the context:\n",
    "    - Shrinking down what you can and throwing away the rest.\n",
    "- Assembling the result into a document that looks like something in the training set.\n",
    "    - Document mimicry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebb24a",
   "metadata": {},
   "source": [
    "## Chat models\n",
    "\n",
    "- Have improved on the above. \n",
    "    - Especial syntax behind the scenes (no need of markdown)\n",
    "    - fine tuned for system messages\n",
    "    - stops correctly\n",
    "- Security backed in:\n",
    "    - no bad words or instructions\n",
    "    - almost no hallucinations of false information\n",
    "    - no prompt injection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e4b0f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Tool usage\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63699c79",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Q&A\n",
    "\n",
    "- How many examples for few-shot learning\n",
    "    - Use log-probs, see if they get high as we add examples and stop adding when it saturates.\n",
    "- Where to put those examples\n",
    "    - As system messages makes them high priority but sometimes we want to put them at the bottom close to the end.\n",
    "        - In this case, we may want to add another *fake* system message after the user one, but the model could get confused in this case. We need to try and evaluate.\n",
    "- Other hyper-parameters:\n",
    "    - When doing evals, use number of completions higher than one to get many possible outputs for the same case so we get a better picture of the type of response we can get. This needs to be done with temperature higher than 0 (but lower than 1).\n",
    "- Getting structure in the message:\n",
    "    - My note: LangChain tackles this at the moment. However, the recommendation from this talk is to not ask to provide an overly complicated structure such as copying and pasting an entire API into the prompt.\n",
    "    - Same about passing very complicated objects (such as nested dictionaries of nested dictionaries and so on) to function tools.\n",
    "- If you have sloppy code the model will probably produce similar style of sloppy (following bad practices) code.\n",
    "- DSP may do a good job of figuring out what are the best examples in few shot learning.\n",
    "- Worth learning about \"*react*\" and \"*reflect*\" as potential techniques aside from chain of thought and few shot. \n",
    "    - The former is the pattern supported in LangChain.\n",
    "    - The latter is to ask \"are you sure this is the right answer\" so that the model does everything in its hands to check the correctness and injects any errors / issues about this answer back to the prompt asking to learn from those mistakes and provide a more accurate answer. It does so several times in a loop and gets a final solution that tends to be much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52e5fe",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "- [Prompt Engineering guide - OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Prompting GPT-5 - OpenAI](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)\n",
    "- [Other prompting resources recommended by OpenAI](https://cookbook.openai.com/articles/related_resources)\n",
    "- [Prompt Engineering - DeepLearning.AI course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)\n",
    "- [Prompt Caching - OpenAI](https://platform.openai.com/docs/guides/prompt-caching)\n",
    "    - [LangChain prompt caching wrapper](https://docs.langchain.com/oss/python/integrations/chat/openai#prompt-caching)\n",
    "- [Building resilient prompts using an evaluation flywheel - OpenAI cookbook](https://cookbook.openai.com/examples/evaluation/building_resilient_prompts_using_an_evaluation_flywheel)\n",
    "- [Prompt baking](https://medium.com/@linz07m/prompt-baking-making-prompts-permanent-in-language-models-662a96092e90)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg2",
   "language": "python",
   "name": "lg2"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
